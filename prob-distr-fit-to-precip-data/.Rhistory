head(data)
xx <- seq(0, 10)
yy <- 2.5*exp(0.4*6xx)
plot(data$x, data$y)
lines(xx, yy, type = "l", col = "red")
x <- seq(1, 9)
y <- c(3.297, 5.437, 8.963, 14.778, 24.365, 40.172, 66.231, 109.196, 180.034)
data <- data.frame(x, y)
head(data)
xx <- seq(0, 10)
yy <- 2.5*exp(0.4*6xx)
plot(data$x, data$y)
lines(xx, yy, type = "l", col = "red")
x <- seq(1, 9)
y <- c(3.297, 5.437, 8.963, 14.778, 24.365, 40.172, 66.231, 109.196, 180.034)
data <- data.frame(x, y)
head(data)
xx <- seq(0, 10)
yy <- 2.5*exp(0.46*xx)
plot(data$x, data$y)
lines(xx, yy, type = "l", col = "red")
x <- seq(1, 9)
y <- c(3.297, 5.437, 8.963, 14.778, 24.365, 40.172, 66.231, 109.196, 180.034)
data <- data.frame(x, y)
head(data)
xx <- seq(0, 10)
yy <- 2.5*exp(0.48*xx)
plot(data$x, data$y)
lines(xx, yy, type = "l", col = "red")
x <- seq(1, 9)
y <- c(3.297, 5.437, 8.963, 14.778, 24.365, 40.172, 66.231, 109.196, 180.034)
data <- data.frame(x, y)
head(data)
xx <- seq(0, 10)
yy <- 2.5*exp(0.47*xx)
plot(data$x, data$y)
lines(xx, yy, type = "l", col = "red")
x <- seq(1, 9)
y <- c(3.297, 5.437, 8.963, 14.778, 24.365, 40.172, 66.231, 109.196, 180.034)
data <- data.frame(x, y)
head(data)
xx <- seq(0, 10)
yy <- 2.45*exp(0.47*xx)
plot(data$x, data$y)
lines(xx, yy, type = "l", col = "red")
x <- seq(1, 9)
y <- c(3.297, 5.437, 8.963, 14.778, 24.365, 40.172, 66.231, 109.196, 180.034)
data <- data.frame(x, y)
head(data)
xx <- seq(0, 10)
yy <- 2.45*exp(0.475*xx)
plot(data$x, data$y)
lines(xx, yy, type = "l", col = "red")
getwd()
5.25-1.75
5.5-0.75
5.25-1.75
5.5-2.75
5.5-1.25
5.5-2.75
getwd()
library(swirl)
rm(list = ls())
swirl()
ls()
class(plants)
dim(plants)
nrow(plants)
ncol
ncol(plants)
object.size(plants)
names(plants)
head(plants)
head(plants, 10)
tail(plants, 15)
summary(plants)
plants$Active_Growth_Period
table(plants$Active_Growth_Period)
str(plants)
0
0
Sys.Date()
mean(c(2, 4, 5))
bye
bye()
swirl()
x <- larv.df.total$temp
78+30+60+60+25
#Clear workspace
rm(list = ls())
#install.packages("rJava")
library("rJava")
#import packages
library(rvest)
library(dplyr)
library(tabulizer)
system("java -version")
#Clear workspace
rm(list = ls())
#install.packages("rJava")
library("rJava")
#import packages
library(rvest)
library(dplyr)
library(tabulizer)
library(tabulizerjars)
# url of the website
site <- "http://www.bccdc.ca/Health-Info-Site/Documents/public-exposures-flights-tables-Archived-2020.pdf"
# default call with no parameters changed
matrix_results <- extract_tables(site)
# default call with no parameters changed
matrix_results <- extract_tables(site)
# get back the tables as data frames, keeping their headers
df_results <- extract_tables(site, output = "data.frame", header = TRUE)
site2 <- "http://www.sedl.org/afterschool/toolkits/science/pdf/ast_sci_data_tables_sample.pdf"
# default call with no parameters changed
matrix_results2 <- extract_tables(site2)
# get back the tables as data frames, keeping their headers
df_results2 <- extract_tables(site2, output = "data.frame", header = TRUE)
#Clear workspace
rm(list = ls())
#install.packages("rJava")
library("rJava")
#import packages
library(rvest)
library(dplyr)
library(tabulizer)
library(tabulizerjars)
# url of the website of the data
site <- "http://www.bccdc.ca/Health-Info-Site/Documents/public-exposures-flights-tables-Archived-2020.pdf"
# default call with no parameters changed
matrix_results <- extract_tables(site)
# Download the pdf file as a variable in R
pdf_text <- pdftools::pdf_text("https://www.acf.hhs.gov/sites/default/files/documents/ocse/fy_2018_annual_report.pdf")
library(pdftools)
library(pdftools)
install.packages("pdftools")
library(plyr)
library(pdftools)
library(plyr)
# Download the pdf file as a variable in R
pdf_text <- pdftools::pdf_text("https://www.acf.hhs.gov/sites/default/files/documents/ocse/fy_2018_annual_report.pdf")
# Focus on the table in page 22
pdf_text22 <- strsplit(pdf_text[[22]], "\n")[[1]]
pdf_text22
# Reformat the table using "regular expression"
pdf_text22 <- strsplit(pdf_text22, " {2,100}")
# Convert the table in a data frame
pdf_text22 <- plyr::rbind.fill(lapply(pdf_text22, function(x) as.data.frame(t(matrix(x)))))
pdf_text22
View(pdf_text22)
# Download the pdf file as a variable in R
pdf_text2 <- pdftools::pdf_text("http://www.bccdc.ca/Health-Info-Site/Documents/public-exposures-flights-tables-Archived-2020.pdf")
# Download the pdf file as a variable in R
pdf_text <- pdftools::pdf_text("http://www.bccdc.ca/Health-Info-Site/Documents/public-exposures-flights-tables-Archived-2020.pdf")
# Focus on the table in page 22
pdf_text <- strsplit(pdf_text, "\n")[[1]]
# Reformat the table using "regular expression"
pdf_text <- strsplit(pdf_text, " {2,100}")
# Convert the table in a data frame
pdf_text <- plyr::rbind.fill(lapply(pdf_text, function(x) as.data.frame(t(matrix(x)))))
View(pdf_text)
# Focus on the table in page 22
pdf_text <- strsplit(pdf_text, "\n")
# Focus on the table in page 22
pdf_text <- strsplit(pdf_text, "\n")[[1]]
# Download the pdf file as a variable in R
pdf_text <- pdftools::pdf_text("http://www.bccdc.ca/Health-Info-Site/Documents/public-exposures-flights-tables-Archived-2020.pdf")
# Focus on the table in page 22
pdf_text <- strsplit(pdf_text, "\n")[[1]]
# Reformat the table using "regular expression"
pdf_text <- strsplit(pdf_text)
# Reformat the table using "regular expression"
pdf_text <- strsplit(pdf_text, " {4,}")
# Convert the table in a data frame
pdf_text <- plyr::rbind.fill(lapply(pdf_text, function(x) as.data.frame(t(matrix(x)))))
View(pdf_text)
# Focus on the table in page 22
pdf_text <- extract_tables(pdf_text)
# Download the pdf file as a variable in R
pdf_text <- pdftools::pdf_text("https://www.acf.hhs.gov/sites/default/files/documents/ocse/fy_2018_annual_report.pdf")
# Focus on the table in page 22
pdf_text22 <- strsplit(pdf_text[[22]], "\n")[[1]]
# Reformat the table using "regular expression"
pdf_text22 <- strsplit(pdf_text22, " {2,100}")
# Convert the table in a data frame
pdf_text22 <- plyr::rbind.fill(lapply(pdf_text22, function(x) as.data.frame(t(matrix(x)))))
library(plyr)
url <- "http://www.bccdc.ca/Health-Info-Site/Documents/public-exposures-flights-tables-Archived-2020.pdf"
url_table <- pdf_text(url)
file <- pdf_text(url)
file
file <- pdf_text(url, output = "data.frame", header = TRUE)
?pdf_text
file <- pdf_text(file, output = "data.frame", header = TRUE)
file <- pdf_text(url, output = "data.frame", header = TRUE)
#install.packages("rJava")
library(rJava)
#import packages
library(rvest)
library(dplyr)
library(tabulizer)
library(tabulizerjars)
# url of the website of the data
site <- "http://www.bccdc.ca/Health-Info-Site/Documents/public-exposures-flights-tables-Archived-2020.pdf"
# default call with no parameters changed
matrix_results <- extract_tables(site)
#Clear workspace
rm(list = ls())
#install.packages("rJava")
library(rJava)
#Clear workspace
rm(list = ls())
#install.packages("rJava")
library(rJava)
library(tabulizer)
library(tidyverse)
# PDF Scrape Tables
endangered_species_scrape <- extract_tables(
file   = "2019-09-23-tabulizer/endangered_species.pdf",
method = "decide",
output = "data.frame")
endangered_species_scrape <- extract_tables(
file   = "http://www.bccdc.ca/Health-Info-Site/Documents/public-exposures-flights-tables-Archived-2020.pdf",
method = "decide",
output = "data.frame")
# PDF Scrape Tables
endangered_species_scrape <- extract_tables(
file   = "http://www.bccdc.ca/Health-Info-Site/Documents/public-exposures-flights-tables-Archived-2020.pdf",
method = "decide",
output = "data.frame")
?extract_tables
link <- "https://www.icnarc.org/DataServices/Attachments/Download/8419d345-c7a1-ea11-9126-00505601089b"
dfr.list <- extract_tables(link, output="data.frame", pages=10:11)
? extract_areas
url <- "http://www.bccdc.ca/Health-Info-Site/Documents/public-exposures-flights-tables-Archived-2020.pdf"
file <- locate_areas(url)
view(file())
view(file)
remotes::install_github(c("ropensci/tabulizerjars", "ropensci/tabulizer"))
PDF Scrape Tables
endangered_species_scrape <- extract_tables(
file   = "http://www.bccdc.ca/Health-Info-Site/Documents/public-exposures-flights-tables-Archived-2020.pdf",
method = "decide",
output = "data.frame")
f <- system.file("examples", "data.pdf", package = "tabulizer")
out1 <- extract_tables(f)
str(out1)
f <- system.file("url", "data.pdf", package = "tabulizer")
out1 <- extract_tables(f)
d <- extract_tables(site, pages=1)
d <- extract_tables("http://www.bccdc.ca/Health-Info-Site/Documents/public-exposures-flights-tables-Archived-2020.pdf", pages=1)
gpi_table <- extract_tables("http://visionofhumanity.org/app/uploads/2018/06/Global-Peace-Index-2018-2.pdf",
output = "data.frame",
pages = c(10,10,10,11,11),
area = list(
c(496, 38, 786, 169),
c(496, 212, 786, 341),
c(496, 380, 786, 508),
c(496, 392, 738, 521),
c(496, 225, 788, 353)
),
guess = FALSE
)
gpi_table <- extract_tables("http://www.bccdc.ca/Health-Info-Site/Documents/public-exposures-flights-tables-Archived-2020.pdf",
output = "data.frame",
pages = c(2,3),
guess = FALSE
)
gpi_table <- extract_tables("http://www.bccdc.ca/Health-Info-Site/Documents/public-exposures-flights-tables-Archived-2020.pdf",
output = "data.frame",
pages = c(2,3),
guess = FALSE
)
?data.table
file <- pdf_data(url)
view(file)
url <- "http://www.bccdc.ca/Health-Info-Site/Documents/public-exposures-flights-tables-Archived-2020.pdf"
file <- pdf_data(url)
file
result <- pdf_text(current_path) %>%
# split filecontent by newline character
str_split("\n") %>%
# convert to tibble and assign unique column names
as_tibble(.name_repair = make.names) %>%
# extract the data of each column by position
mutate(
rank = str_sub(X, 0, 5),
movie = str_sub(X, 6, 55),
distributor = str_sub(X, 56, 67),
screens = str_sub(X, 68, 75),
admissions = str_sub(X, 76, 92),
total = str_sub(X, 93)
) %>%
# remove original string
select(-X) %>%
# remove white spaces around values
mutate_all(str_trim)
#Clear workspace
rm(list = ls())
#install.packages("rJava")
library(rJava)
#import packages
#library(rvest)
library(dplyr)
library(tabulizer)
library(tabulizerjars)
library(tidyverse)
# url of the website of the data
site <- "http://www.bccdc.ca/Health-Info-Site/Documents/public-exposures-flights-tables-Archived-2020.pdf"
# default call with no parameters changed
matrix_results <- extract_tables(site)
site
extract_tables(site)
# url of the website of the data
site <- "http://www.bccdc.ca/Health-Info-Site/Documents/public-exposures-flights-tables-Archived-2020.pdf"
# simple demo file
f <- system.file("site", "data.pdf", package = "tabulizer")
# extract all tables
extract_tables(f)
# simple demo file
f <- system.file("examples", "data.pdf", package = "tabulizer")
# extract all tables
extract_tables(f)
# simple demo file
f <- system.file("examples", "data.pdf", package = "tabulizer")
# extract all tables
extract_tables(f)
# extract tables from only second page
extract_tables(f, pages = 2)
# extract areas from a page
## full table
extract_tables(f, pages = 2, area = list(c(126, 149, 212, 462)))
## part of the table
extract_tables(f, pages = 2, area = list(c(126, 284, 174, 417)))
library(pdftools)
library(plyr)
# Download the pdf file as a variable in R
pdf_text <- pdftools::pdf_text("https://www.acf.hhs.gov/sites/default/files/documents/ocse/fy_2018_annual_report.pdf")
# Focus on the table in page 22
pdf_text22 <- strsplit(pdf_text[[22]], "\n")[[1]]
# Reformat the table using "regular expression"
pdf_text22 <- strsplit(pdf_text22, " {2,100}")
# Convert the table in a data frame
pdf_text22 <- plyr::rbind.fill(lapply(pdf_text22, function(x) as.data.frame(t(matrix(x)))))
pdf_text22
url <- "http://www.bccdc.ca/Health-Info-Site/Documents/public-exposures-flights-tables-Archived-2020.pdf"
file <- pdf_data(url)
file
# PDF Scrape Tables
endangered_species_scrape <- extract_tables(
file   = "http://www.bccdc.ca/Health-Info-Site/Documents/public-exposures-flights-tables-Archived-2020.pdf",
method = "decide",
output = "data.frame")
if (!require("remotes")) {
install.packages("remotes")
}
# url of the website of the data
site <- "http://www.bccdc.ca/Health-Info-Site/Documents/public-exposures-flights-tables-Archived-2020.pdf"
# default call with no parameters changed
matrix_results <- extract_tables(site)
?extract_tables
# simple demo file
f <- system.file("examples", "data.pdf", package = "tabulizer")
# extract all tables
extract_tables(f)
library(tidyverse)
library(rJava)
f <- system.file("examples", "data.pdf", package = "tabulizer")
# extract all tables
extract_tables(f)
# Download the pdf file as a variable in R
pdf_text <- pdftools::pdf_text("https://www.acf.hhs.gov/sites/default/files/documents/ocse/fy_2018_annual_report.pdf")
# Focus on the table in page 22
pdf_text22 <- strsplit(pdf_text[[22]], "\n")[[1]]
pdf_text22
# Reformat the table using "regular expression"
pdf_text22 <- strsplit(pdf_text22, " {2,100}")
# Convert the table in a data frame
pdf_text22 <- plyr::rbind.fill(lapply(pdf_text22, function(x) as.data.frame(t(matrix(x)))))
pdf_text22
1569/(12*4)
1569/(12)
130.75/4
list.files()
20*09
20*0.9
20*(1-0.1)
?sample
sample(1:10, 5, replace = FALSE)
sample(1:10, 5, replace = TRUE)
?rexp
dexp(1)
dexp(2)
dexp(1:3)
source('~/Desktop/Mosquito population dynamics/mosquito_population/mosquito_model.R', echo=TRUE)
egg.mortality(t)
mean(egg.mortality(t))
mean(larva.mortality(t))
mean(pupa.mortality(t))
mean(adult.mortality(t))
261.15*8
271.15*8
#Clear workspace
rm(list = ls())
#Clear workspace
rm(list = ls())
# Import packages into r
library(tidyverse)
library(scales)
library(dplyr)
library(chron)
library(ggplot2)
# Time series plot of temperature
climate.df <- read.csv("/Users/jbaafi/Documents/climate-and-mosquitoes/mosq-pop-prediction-model/climate.df.csv")
View(climate.df)
ggplot(data = climate.df, mapping = aes(x=Chron.Date, y=Mean.Temp))+
geom_line(colour = "steelblue")+
theme_classic()+
xlab("Time (Days)")+
ylab("Mean Temperature")+
theme(axis.text.x=element_text(angle=45, hjust=1))
plot(climate.df$Days.Since.Origin, climate.df$Mean.Temp, type = "l")
plot(climate.df$Days.Since.Origin, climate.df$Mean.Temp, type = "l", col = "red")
plot(climate.df$Days.Since.Origin, climate.df$Mean.Temp, type = "l", col = "blue")
plot(climate.df$Days.Since.Origin, climate.df$Mean.Temp, col = "blue")
plot(climate.df$Days.Since.Origin, climate.df$Mean.Temp, col = "blue", type = "l")
# Time series plot of total precipitation
plot(climate.df$Days.Since.Origin, climate.df$Total.Precip, col = "blue", type = "l")
# Time series plot of total precipitation
plot(climate.df$Days.Since.Origin, climate.df$Total.Precip, col = "blue")
# Fitting function to data of mean temperature
Time <- climate.df$Days.Since.Origin
Temp <- climate.df$Mean.Temp
#Define a periodic function to fit to data
Temp.func <- sin(2*pi*Time/365) + cos(2*pi*Time/365)
fit.lm <- lm(Temp~Temp.func)
fit <- fitted(fit.lm)
# find predictions for original time series
pred <- predict(fit.lm, newdata=data.frame(Time=Time))
#Plotting the data with fitted function with the base plot function
plot(Temp ~ Days.Since.Origin, data= climate.df)
lines(fit, col="red")
lines(Time, pred, col="blue")
summary(fit.lm)
#Plotting same data as above with ggplot2
ggplot(data = climate.df)+
geom_point(mapping = aes(x=Days.Since.Origin, y=Mean.Temp))+
geom_line(mapping = aes(x=Days.Since.Origin, y=fit, colour="red"))+
geom_line(mapping = aes(x=Time, y=pred, colour="blue"))
a <- mean(climate.df$Mean.Temp)
b1 <- -8.7635
f <- a + b1*sin(2*pi*Time/365) + b1*cos(2*pi*Time/365)
plot(Temp~Days.Since.Origin, data = climate.df)
lines(Time, f, col = "red")
# clear workspace
rm(list=ls())
getwd()
# Set working directory
setwd("/Users/jbaafi/Documents/climate-and-mosquitoes/prob-distr-fit-to-precip-data")
# Import packages needed
packages <- c("tidyverse", "stringr", "dplyr", "base",
"ggplot2", "patchwork", "bbmle", "fitdistrplus")
lapply(packages, require, character.only = TRUE)
# Load data
precip <- read.csv(file = "climate.df.csv")
# Histogram of total precipitation
hist(precip$Total.Precip, breaks = 100)
# Subset the data for total precip = 0
zero.precip <- precip[(precip$Total.Precip==0),]
# Subset the data for total precip = 0
zero.precip <- precip[(precip$Total.Precip==0),]
# Sum the rows with zero precipitation
sum(precip$Total.Precip==0)
2127-1134
# Subset the data for total precip = 0
zero.precip <- precip[(precip$Total.Precip==0),]
# Sum the rows with zero precipitation
sum(precip$Total.Precip==0)
# Eliminate zero recordings with dplyr
df <- precip %>%
filter(Total.Precip != 0 & !is.na(Total.Precip) & Total.Precip <= 50) %>%
arrange(Total.Precip)
# Plot histogram of precipitation from df data
hist.df <-  hist(df$Total.Precip, breaks = 100, plot = T)
# Plot precipitation mid on x-axis and frequency on y-axis
plot(hist.df$mids, hist.df$counts, type = "l")
# Plot densities of various points
plot(hist.df$mids, hist.df$density, type = "l")
# Save data into df2
df2 <- data.frame(hist.df$mids, hist.df$counts, hist.df$density)
# Change column names
df2 <- df2 %>%
rename(precip = hist.df.mids, freq = hist.df.counts, density = hist.df.density)
# Assign data to x and y
x <- df2$precip
y <- df2$density
# ------- Use the nls() (non-linear least squares) function to fit exponential function to data
exp <- nls(y ~ lambda*exp(-lambda*x), data = df2, start = list(lambda = 0.67))
# Plot the fit results
plot(x, y, col = "blue", ylim = c(0, 0.7), pch = 19)
lines(x, predict(exp), col="red")
# Run a summary of the fit and obtain the parameter estimate
summary(exp)
coef(exp)
# Fit the log-normal PDF to data by the nls() function.
logn <- nls(y ~ (1/(x*delta*sqrt(2*pi)))*exp(-((log(x)-mu)^2)/(2*delta^2)), data = df2, start = list(mu = 0.499, delta = 1.2))
#Plot
plot(x, y, col = "blue", ylim = c(0, 0.7), pch = 19)
lines(x, predict(logn), col="red")
# Get the summary of the fit
summary(logn)
